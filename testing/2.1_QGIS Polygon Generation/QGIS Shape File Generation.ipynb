{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "956739fc-8f5f-44b1-a794-8ca972055d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rotated_rectangle(center, width, height, angle, crs=\"EPSG:4326\"):\n",
    "    \"\"\"\n",
    "    Create a rotated rectangle as a polygon in geographic coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "        center (tuple): The (longitude, latitude) coordinates of the centroid.\n",
    "        width (float): The width of the rectangle.\n",
    "        height (float): The height of the rectangle.\n",
    "        angle (float): The rotation angle in degrees (counterclockwise).\n",
    "        crs (str): Coordinate reference system for geographic coordinates (default: EPSG:4326).\n",
    "    \n",
    "    Returns:\n",
    "        dict: GeoJSON-like structure containing the rectangle coordinates in longitude and latitude.\n",
    "    \"\"\"\n",
    "    # Create rectangle corners centered at (0, 0) in a planar space\n",
    "    rectangle = Polygon([\n",
    "        (-width / 2, -height / 2),\n",
    "        (width / 2, -height / 2),\n",
    "        (width / 2, height / 2),\n",
    "        (-width / 2, height / 2),\n",
    "        (-width / 2, -height / 2)\n",
    "    ])\n",
    "    \n",
    "    # Rotate the rectangle\n",
    "    rotated_rectangle = rotate(rectangle, angle, origin=(0, 0), use_radians=False)\n",
    "    \n",
    "    # Translate the rectangle to the given center\n",
    "    translated_rectangle = translate(rotated_rectangle, xoff=center[0], yoff=center[1])\n",
    "    \n",
    "    # Convert planar coordinates to geographic coordinates (if needed)\n",
    "    transformer = Transformer.from_crs(crs, crs, always_xy=True)  # Ensure geographic CRS\n",
    "    geographic_coords = [\n",
    "        transformer.transform(x, y) for x, y in translated_rectangle.exterior.coords\n",
    "    ]\n",
    "    \n",
    "    # Return as GeoJSON-like dictionary\n",
    "    return {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [geographic_coords]\n",
    "    }\n",
    "    \n",
    "# Convert the 'geometry' column to MULTIPOLYGON\n",
    "def convert_to_multipolygon(geojson_dict):\n",
    "    # Convert GeoJSON-like dict to Shapely geometry\n",
    "    polygon = shape(geojson_dict)\n",
    "    \n",
    "    # Ensure the geometry is a MULTIPOLYGON\n",
    "    if polygon.geom_type == \"Polygon\":\n",
    "        return MultiPolygon([polygon])\n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "972d1875-2427-4386-af81-c3e04c398cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "oats_points.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load your GeoJSON file with points (Replace 'points.geojson' with your file path)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(geojson_file)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set your desired width, height, and rotation angle (in degrees)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00008\u001b[39m  \u001b[38;5;66;03m# Specify width of the rectangle\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\geopandas\\io\\file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[0;32m    295\u001b[0m         filename, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, columns\u001b[38;5;241m=\u001b[39mcolumns, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\geopandas\\io\\file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyogrio\u001b[38;5;241m.\u001b[39mread_dataframe(path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyogrio\\geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m read_func(\n\u001b[0;32m    266\u001b[0m     path_or_buffer,\n\u001b[0;32m    267\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    268\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    269\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    270\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[0;32m    271\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mgdal_force_2d,\n\u001b[0;32m    272\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[0;32m    273\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features,\n\u001b[0;32m    274\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    275\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m    276\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    277\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[0;32m    278\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[0;32m    279\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[0;32m    280\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mfid_as_index,\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    282\u001b[0m )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyogrio\\raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ogr_read(\n\u001b[0;32m    199\u001b[0m     get_vsi_path_or_buffer(path_or_buffer),\n\u001b[0;32m    200\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    201\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    202\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    203\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[0;32m    204\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mforce_2d,\n\u001b[0;32m    205\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[0;32m    206\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    207\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    208\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m    209\u001b[0m     mask\u001b[38;5;241m=\u001b[39m_mask_to_wkb(mask),\n\u001b[0;32m    210\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[0;32m    211\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[0;32m    212\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[0;32m    213\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mreturn_fids,\n\u001b[0;32m    214\u001b[0m     dataset_kwargs\u001b[38;5;241m=\u001b[39mdataset_kwargs,\n\u001b[0;32m    215\u001b[0m     datetime_as_string\u001b[38;5;241m=\u001b[39mdatetime_as_string,\n\u001b[0;32m    216\u001b[0m )\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDataSourceError\u001b[0m: oats_points.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Load your GeoJSON file with points (Replace 'points.geojson' with your file path)\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "# Set your desired width, height, and rotation angle (in degrees)\n",
    "width = 0.00008  # Specify width of the rectangle\n",
    "height = 0.000009  # Specify height of the rectangle\n",
    "rotation = 6  # Specify rotation angle in degrees\n",
    "\n",
    "# Create a new column for the generated polygons\n",
    "gdf['polygons'] = gdf.geometry.apply(lambda point: create_rotated_rectangle((point.x, point.y), width, height, rotation))\n",
    "gdf.drop(columns=[\"geometry\"], inplace=True)\n",
    "gdf.rename(columns={\"polygons\": \"geometry\"}, inplace=True)\n",
    "\n",
    "# Apply conversion of geometry format\n",
    "gdf['geometry'] = gdf['geometry'].apply(convert_to_multipolygon)\n",
    "\n",
    "# Ensure your GeoDataFrame has a CRS\n",
    "gdf.set_crs(\"EPSG:4326\", inplace=True)  # WGS84 CRS\n",
    "# Save the resulting GeoDataFrame as a new GeoJSON file\n",
    "gdf.to_file(output_file_skewed, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f32251-093b-4e2b-8857-cc3057776bf2",
   "metadata": {},
   "source": [
    "# Shrink the sowing polygons (without rotating them) to get the extraction polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d9b57-4cf8-40d4-9ec5-3c09ad946fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.affinity import scale\n",
    "\n",
    "def shrink_geometry(geometry, x_factor, y_factor):\n",
    "    \"\"\"\n",
    "    Shrink a polygon's geometry by independent x and y scaling factors.\n",
    "\n",
    "    Parameters:\n",
    "        geometry (shapely.geometry): The polygon geometry to shrink.\n",
    "        x_factor (float): Scaling factor for the x-axis.\n",
    "        y_factor (float): Scaling factor for the y-axis.\n",
    "\n",
    "    Returns:\n",
    "        shapely.geometry: The scaled polygon geometry.\n",
    "    \"\"\"\n",
    "    centroid = geometry.centroid  # Get the centroid of the polygon\n",
    "    # Scale the polygon relative to its centroid\n",
    "    return scale(geometry, xfact=x_factor, yfact=y_factor, origin=(centroid.x, centroid.y))\n",
    "\n",
    "def shrink_polygons(input_file, x_factor=0.9, y_factor=0.9):\n",
    "    \"\"\"\n",
    "    Shrink polygons in a GeoJSON file by independent x and y scaling factors.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input GeoJSON file.\n",
    "        x_factor (float): Scaling factor for the x-axis (e.g., 0.9 for 90% size).\n",
    "        y_factor (float): Scaling factor for the y-axis (e.g., 0.9 for 90% size).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the GeoJSON as a GeoDataFrame\n",
    "    gdf = input_file\n",
    "\n",
    "    # Apply scaling to each polygon in the GeoDataFrame\n",
    "    gdf['geometry'] = gdf['geometry'].apply(lambda geom: shrink_geometry(geom, x_factor, y_factor))\n",
    "\n",
    "    # Save the updated GeoDataFrame to a new GeoJSON file\n",
    "    return gdf\n",
    "\n",
    "# # Example usage\n",
    "# input_geojson = gpd.read_file(\"gene2bread.geojson\")\n",
    "# output_geojson = \"shrunk_polygons.geojson\"\n",
    "\n",
    "# # Load your GeoJSON file with points\n",
    "\n",
    "# shrunk_gdf = shrink_polygons(input_geojson, x_factor=0.8, y_factor=0.7)\n",
    "# shrunk_gdf\n",
    "# shrunk_gdf.to_file(output_geojson, driver=\"GeoJSON\")  # Save updated GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e61b19-763c-4e56-a765-a4dbb594574c",
   "metadata": {},
   "source": [
    "# Shrink and rotate the sowing polygons to get the extraction polygons. Corrected where it was skeweing if the x and y factor were not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f599570-4f7f-45a9-b8d8-9d02fc34b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.affinity import rotate, scale\n",
    "from shapely.geometry import shape\n",
    "from pyproj import Transformer, CRS\n",
    "from shapely.ops import transform\n",
    "import geopandas as gpd\n",
    "\n",
    "def scale_and_rotate_polygons(gdf, x_factor, y_factor, angle, input_crs=\"EPSG:4326\", output_crs=\"EPSG:3857\"):\n",
    "    \"\"\"\n",
    "    Scale and rotate polygons in a GeoDataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        gdf (GeoDataFrame): GeoDataFrame with polygons.\n",
    "        x_factor (float): Scaling factor for the x-axis.\n",
    "        y_factor (float): Scaling factor for the y-axis.\n",
    "        angle (float): Rotation angle in degrees (counterclockwise).\n",
    "        input_crs (str): The original CRS of the data (default: EPSG:4326).\n",
    "        output_crs (str): The projected CRS for transformations (default: EPSG:3857).\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: Updated GeoDataFrame with scaled and rotated polygons.\n",
    "    \"\"\"\n",
    "    # Initialize transformers for CRS transformations\n",
    "    transformer_to_planar = Transformer.from_crs(input_crs, output_crs, always_xy=True)\n",
    "    transformer_to_geo = Transformer.from_crs(output_crs, input_crs, always_xy=True)\n",
    "    \n",
    "    def transform_geometry(geometry):\n",
    "        # Transform the geometry to a planar CRS\n",
    "        planar_geom = transform(lambda x, y: transformer_to_planar.transform(x, y), geometry)\n",
    "        \n",
    "        # Uniformly scale the geometry in the planar CRS to avoid skew\n",
    "        uniform_scaled_geom = scale(planar_geom, xfact=(x_factor + y_factor) / 2, yfact=(x_factor + y_factor) / 2, origin='center')\n",
    "        \n",
    "        # Rotate the geometry\n",
    "        rotated_geom = rotate(uniform_scaled_geom, angle, origin='center', use_radians=False)\n",
    "        \n",
    "        # Transform the geometry back to the geographic CRS\n",
    "        geo_geom = transform(lambda x, y: transformer_to_geo.transform(x, y), rotated_geom)\n",
    "        return geo_geom\n",
    "    \n",
    "    # Apply the transformation to each geometry in the GeoDataFrame\n",
    "    gdf['geometry'] = gdf['geometry'].apply(transform_geometry)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# # Step 1: Read GeoJSON file\n",
    "# input_file = \"gene2bread.geojson\"\n",
    "# output_file = \"transform________d_polygons.geojson\"\n",
    "# gdf = gpd.read_file(input_file)\n",
    "\n",
    "# # Apply scaling and rotation\n",
    "# scaled_rotated_gdf = scale_and_rotate_polygons(\n",
    "#     gdf, x_factor=0.9, y_factor=0.8, angle=0.5, input_crs=\"EPSG:4326\", output_crs=\"EPSG:3857\"\n",
    "# )\n",
    "\n",
    "# # Save updated GeoDataFrame to GeoJSON\n",
    "# scaled_rotated_gdf.to_file(\"scaled_rotated_po lygons.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47a5c7-d1f6-4a8b-a66e-3bbcf01add1e",
   "metadata": {},
   "source": [
    "# NOTE: Although shrinking the polygons work but it is tricky to independelty change the x_factor without disturbing the y_facotr and viceversa since the fields and eventually the polygons are not aligned with the coordinates axis. So, the best approach would be to find the centroids of the sowing polygons and create the shrinked polygons aroung those centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15786aeb-8eef-421d-bb4b-6f0a6b476a4c",
   "metadata": {},
   "source": [
    "# FINAL APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab212bf7-c977-49fb-b537-2509fd880fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "from pyproj import Transformer, CRS\n",
    "from shapely.affinity import rotate, translate\n",
    "from shapely.geometry import Point, Polygon, shape, MultiPolygon, MultiPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d13b40-da9b-476a-b31e-4424eb7fe64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the tif files in a given folderÂ¶\n",
    "def find_files_in_folder(folder_path, extension=None, recursive=False):\n",
    "    \"\"\"\n",
    "    Retrieves a list of file paths in a specified folder, optionally filtered by file extension,\n",
    "    and optionally including subdirectories.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): The path of the folder to search for files.\n",
    "    - extension (str, optional): The file extension to filter by (e.g., \"txt\" or \"tif\").\n",
    "                                 If None, the function lists all files.\n",
    "    - recursive (bool, optional): If True, includes files from all subdirectories within `folder_path`.\n",
    "                                  Defaults to False (only lists files in the specified folder).\n",
    "\n",
    "    Returns:\n",
    "    - list of str: A list of file paths that match the specified extension in the folder.\n",
    "                   If no matching files are found, returns a list containing an empty string.\n",
    "\n",
    "    Example:\n",
    "    >>> find_files_in_folder(\"/path/to/folder\", \"tif\")\n",
    "    ['/path/to/folder/file1.tif', '/path/to/folder/file2.tif']\n",
    "\n",
    "    >>> find_files_in_folder(\"/path/to/folder\", recursive=True)\n",
    "    ['/path/to/folder/file1.tif', '/path/to/folder/subfolder/file2.txt', '/path/to/folder/file3.jpg']\n",
    "    \"\"\"\n",
    "    \n",
    "    matched_files = []\n",
    "\n",
    "    # Determine the search pattern based on whether an extension is provided and recursion is enabled\n",
    "    if extension:\n",
    "        if recursive:\n",
    "            search_pattern = os.path.join(folder_path, f\"**/*.{extension}\")\n",
    "        else:\n",
    "            search_pattern = os.path.join(folder_path, f\"*.{extension}\")\n",
    "    else:\n",
    "        # No extension specified, handle both recursive and non-recursive cases\n",
    "        if recursive:\n",
    "            search_pattern = os.path.join(folder_path, \"**/*\")\n",
    "        else:\n",
    "            search_pattern = os.path.join(folder_path, \"*\")\n",
    "    \n",
    "    # Use glob to find matching files in the specified directory and subdirectories if recursive\n",
    "    matched_files.extend(glob.glob(search_pattern, recursive=recursive))\n",
    "    \n",
    "    # If no files are found, return a list with an empty string\n",
    "    if not matched_files:\n",
    "        matched_files = [\"\"]\n",
    "\n",
    "    return matched_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f6eb4d-81bd-4d7a-b84e-0f21d0c11898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygons_to_centroids(input_geojson, output_geojson):\n",
    "    \"\"\"\n",
    "    Convert a GeoJSON file of polygons to a GeoJSON file of centroid points.\n",
    "    \n",
    "    Parameters:\n",
    "        input_geojson (str): Path to the input GeoJSON file containing polygons.\n",
    "        output_geojson (str): Path to the output GeoJSON file containing centroid points.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the GeoJSON file as a GeoDataFrame\n",
    "    gdf = gpd.read_file(input_geojson)\n",
    "    \n",
    "    # Calculate centroids for each polygon\n",
    "    gdf['geometry'] = gdf['geometry'].centroid\n",
    "    \n",
    "    # Ensure geometries are now Point objects\n",
    "    if not all(isinstance(geom, Point) for geom in gdf['geometry']):\n",
    "        raise ValueError(\"Not all geometries are centroids (points).\")\n",
    "    \n",
    "    # Save the GeoDataFrame with centroids as a new GeoJSON file\n",
    "    gdf.to_file(output_geojson, driver='GeoJSON')\n",
    "\n",
    "\n",
    "\n",
    "# Reorder the centroids\n",
    "def reorder_points_by_columns(input_geojson, output_geojson, rotation_angle=0):\n",
    "    \"\"\"\n",
    "    Reorder points in a GeoJSON file such that points are ordered column-first.\n",
    "    The rotation is used only for ordering purposes; the final output retains original coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "        input_geojson (str): Path to the input GeoJSON file containing points.\n",
    "        output_geojson (str): Path to the output GeoJSON file with reordered points.\n",
    "        rotation_angle (float): Angle in degrees to rotate the grid for ordering (default: 0).\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load GeoJSON file into a GeoDataFrame\n",
    "    gdf = gpd.read_file(input_geojson)\n",
    "    \n",
    "    # Compute the centroid of the whole grid\n",
    "    grid_centroid = MultiPoint(gdf.geometry).centroid\n",
    "    \n",
    "    # Rotate the points temporarily for ordering\n",
    "    if rotation_angle != 0:\n",
    "        gdf['rotated_geometry'] = gdf['geometry'].apply(\n",
    "            lambda geom: rotate(geom, rotation_angle, origin=grid_centroid, use_radians=False)\n",
    "        )\n",
    "    else:\n",
    "        gdf['rotated_geometry'] = gdf['geometry']\n",
    "    \n",
    "    # Extract coordinates from rotated geometries for sorting\n",
    "    gdf['x'] = gdf['rotated_geometry'].apply(lambda geom: geom.x)\n",
    "    gdf['y'] = gdf['rotated_geometry'].apply(lambda geom: geom.y)\n",
    "    \n",
    "    # Sort by x (columns) first, and then by y (rows) within each column\n",
    "    gdf_sorted = gdf.sort_values(by=['x', 'y'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # Drop geometry column for exporting the rotated geometry\n",
    "    gdf_rotated_geometry_sorted = gdf_sorted.drop(columns=['geometry', 'x', 'y'])\n",
    "    gdf_rotated_geometry_sorted.rename(columns={\"rotated_geometry\": \"geometry\"}, inplace=True)\n",
    "\n",
    "    # Save the rotated GeoDataFrame as a new GeoJSON file\n",
    "    gdf_rotated_geometry_sorted.to_file(modify_filename(output_geojson, suffix = \"_rotated_geometry\"), driver=\"GeoJSON\")\n",
    "    \n",
    "    # Drop temporary columns for sorting\n",
    "    gdf_sorted = gdf_sorted.drop(columns=['rotated_geometry', 'x', 'y'])\n",
    "    \n",
    "    # Save the reordered GeoDataFrame as a new GeoJSON file\n",
    "    gdf_sorted.to_file(output_geojson, driver=\"GeoJSON\")\n",
    "\n",
    "def update_ids(input_geojson, output_centroids_with_IDs, id_start=100, id_end=111, step=100):\n",
    "    \"\"\"\n",
    "    Update the IDs of entries in a GeoDataFrame following a specific sequence.\n",
    "\n",
    "    Parameters:\n",
    "        gdf (GeoDataFrame): Input GeoDataFrame.\n",
    "        id_start (int): Starting value for each sequence.\n",
    "        id_end (int): Ending value (inclusive) for each sequence.\n",
    "        step (int): Step to increase the starting value after each sequence.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: Updated GeoDataFrame with modified IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    gdf = gpd.read_file(input_geojson)\n",
    "\n",
    "    id_list = []\n",
    "    current_start = id_start\n",
    "\n",
    "    while len(id_list) < len(gdf):\n",
    "        id_list.extend(range(current_start, current_start + (id_end - id_start) + 1))\n",
    "        current_start += step\n",
    "\n",
    "    # Ensure the ID list matches the length of the GeoDataFrame\n",
    "    id_list = id_list[:len(gdf)]\n",
    "    gdf['ID'] = id_list\n",
    "\n",
    "    gdf.to_file(output_centroids_with_IDs, driver=\"GeoJSON\")  # Save updated GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b826c5-43f9-4759-99b4-26fb6b2814e8",
   "metadata": {},
   "source": [
    "# Correct coordinates system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba85f0a8-e033-49c6-b3e2-f2702e723cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the coordinates of a certain sowing geojson are not in longlat; use this funciton to convert them to longlat\n",
    "\n",
    "def convert_utm_to_longlat(input_geojson, output_geojson, utm_zone):\n",
    "    \"\"\"\n",
    "    Convert a GeoJSON file with UTM coordinates to Latitude/Longitude (WGS84).\n",
    "    \n",
    "    Parameters:\n",
    "        input_geojson (str): Path to the input GeoJSON file with UTM coordinates.\n",
    "        output_geojson (str): Path to the output GeoJSON file with WGS84 coordinates.\n",
    "        utm_zone (int): UTM zone number for the input coordinates (positive for north, negative for south).\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the GeoJSON file as a GeoDataFrame\n",
    "    gdf = gpd.read_file(input_geojson)\n",
    "    \n",
    "    # Define the source CRS as the UTM zone (EPSG code)\n",
    "    if utm_zone > 0:\n",
    "        source_crs = CRS.from_epsg(32600 + utm_zone)  # Northern hemisphere\n",
    "    else:\n",
    "        source_crs = CRS.from_epsg(32700 - utm_zone)  # Southern hemisphere\n",
    "    \n",
    "    # Set the GeoDataFrame's CRS\n",
    "    gdf = gdf.set_crs(source_crs)\n",
    "    \n",
    "    # Convert to WGS84 (longitude/latitude)\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Save the converted GeoDataFrame to a new GeoJSON file\n",
    "    gdf.to_file(output_geojson, driver=\"GeoJSON\")\n",
    "\n",
    "# # Path to the input and output GeoJSON files\n",
    "# input_geojson = \"path_to_utm_file.geojson\"\n",
    "# output_geojson = \"path_to_longlat_file.geojson\"\n",
    "\n",
    "# # Specify the UTM zone of the input data (e.g., zone 33N is 33, zone 33S is -33)\n",
    "# utm_zone = 32\n",
    "\n",
    "# # Convert the GeoJSON\n",
    "# convert_utm_to_longlat(input_geojson, output_geojson, utm_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d777d9c3-4bec-4836-9ad9-50fc184b46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rotated_rectangle(center, width, height, angle, crs=\"EPSG:4326\"):\n",
    "    \"\"\"\n",
    "    Create a rotated rectangle as a polygon in geographic coordinates around the given center point.\n",
    "    \n",
    "    Parameters:\n",
    "        center (tuple): The (longitude, latitude) coordinates of the centroid.\n",
    "        width (float): The width of the rectangle (in meters or appropriate planar units).\n",
    "        height (float): The height of the rectangle (in meters or appropriate planar units).\n",
    "        angle (float): The rotation angle in degrees (counterclockwise).\n",
    "        crs (str): Coordinate reference system for geographic coordinates (default: EPSG:4326).\n",
    "    \n",
    "    Returns:\n",
    "        dict: GeoJSON-like structure containing the rectangle coordinates in longitude and latitude.\n",
    "    \"\"\"\n",
    "    # Define a planar CRS (e.g., UTM zone based on the center point)\n",
    "    transformer_to_planar = Transformer.from_crs(crs, CRS(\"EPSG:3857\"), always_xy=True)\n",
    "    transformer_to_geo = Transformer.from_crs(CRS(\"EPSG:3857\"), crs, always_xy=True)\n",
    "\n",
    "    # Transform the center to planar coordinates\n",
    "    center_planar = transformer_to_planar.transform(center[0], center[1])\n",
    "    \n",
    "    # Create rectangle corners centered at (0, 0) in the planar space\n",
    "    rectangle = Polygon([\n",
    "        (-width / 2, -height / 2),\n",
    "        (width / 2, -height / 2),\n",
    "        (width / 2, height / 2),\n",
    "        (-width / 2, height / 2),\n",
    "        (-width / 2, -height / 2)\n",
    "    ])\n",
    "    \n",
    "    # Rotate the rectangle\n",
    "    rotated_rectangle = rotate(rectangle, angle, origin=(0, 0), use_radians=False)\n",
    "    \n",
    "    # Translate the rectangle to the given center in planar coordinates\n",
    "    translated_rectangle = translate(rotated_rectangle, xoff=center_planar[0], yoff=center_planar[1])\n",
    "    \n",
    "    # Convert planar coordinates back to geographic coordinates\n",
    "    geographic_coords = [\n",
    "        transformer_to_geo.transform(x, y) for x, y in translated_rectangle.exterior.coords\n",
    "    ]\n",
    "    \n",
    "    # Return as GeoJSON-like dictionary\n",
    "    return {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [geographic_coords]\n",
    "    }\n",
    "\n",
    "# Convert the 'geometry' column to MULTIPOLYGON\n",
    "def convert_to_multipolygon(geojson_dict):\n",
    "    # Convert GeoJSON-like dict to Shapely geometry\n",
    "    polygon = shape(geojson_dict)\n",
    "    \n",
    "    # Ensure the geometry is a MULTIPOLYGON\n",
    "    if polygon.geom_type == \"Polygon\":\n",
    "        return MultiPolygon([polygon])\n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259b9ef6-346d-4c98-a285-b3c48f35c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shrinked_polygons(\n",
    "    input_centroids_with_IDs,\n",
    "    output_extraction_polygons,\n",
    "    width,\n",
    "    height,\n",
    "    rotation,\n",
    "    crs=\"EPSG:4326\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate shrinked polygons around centroids, save them to a GeoJSON file, and apply transformations.\n",
    "\n",
    "    Parameters:\n",
    "        input_centroids_with_IDs (str): Path to the input GeoJSON file with centroids and IDs.\n",
    "        output_extraction_polygons (str): Path to the output GeoJSON file for the polygons.\n",
    "        width (float): Width of the polygons to generate.\n",
    "        height (float): Height of the polygons to generate.\n",
    "        rotation (float): Rotation angle of the polygons in degrees.\n",
    "        crs (str): Coordinate Reference System for the GeoDataFrame (default: \"EPSG:4326\").\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the GeoJSON file with centroids and IDs\n",
    "    gdf = gpd.read_file(input_centroids_with_IDs)\n",
    "\n",
    "    # Create shrinked polygons based on the centroids\n",
    "    gdf['polygons'] = gdf.geometry.apply(\n",
    "        lambda point: create_rotated_rectangle(\n",
    "            (point.x, point.y), width, height, rotation\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Replace the geometry column with the generated polygons\n",
    "    gdf.drop(columns=[\"geometry\"], inplace=True)\n",
    "    gdf.rename(columns={\"polygons\": \"geometry\"}, inplace=True)\n",
    "    \n",
    "    # Convert the polygons to MultiPolygon format\n",
    "    gdf['geometry'] = gdf['geometry'].apply(convert_to_multipolygon)\n",
    "    \n",
    "    # Ensure the GeoDataFrame has a valid CRS\n",
    "    gdf.set_crs(crs, inplace=True)\n",
    "    \n",
    "    # Save the resulting GeoDataFrame as a GeoJSON file\n",
    "    gdf.to_file(output_extraction_polygons, driver='GeoJSON')\n",
    "\n",
    "    print(f\"Shrinked polygons saved to {output_extraction_polygons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41242a6-3895-4278-8d1e-5f5f98222882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modify_filename(filepath, prefix=None, suffix=None, subfolder=None):\n",
    "    \"\"\"\n",
    "    Modify a file path by adding a prefix, suffix, and optionally creating a new subfolder.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): The original file path.\n",
    "        prefix (str, optional): Text to add before the file name. Defaults to None.\n",
    "        suffix (str, optional): Text to add before the file extension. Defaults to None.\n",
    "        subfolder (str, optional): Name of a subfolder to include in the path. If provided, the subfolder will be created if it doesn't exist.\n",
    "\n",
    "    Returns:\n",
    "        str: The modified file path.\n",
    "    \"\"\"\n",
    "    # Split the file path into directory, filename, and extension\n",
    "    dir_path, filename = os.path.split(filepath)\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    \n",
    "    # Add the subfolder if provided\n",
    "    if subfolder:\n",
    "        dir_path = os.path.join(dir_path, subfolder)\n",
    "        os.makedirs(dir_path, exist_ok=True)  # Create the subfolder if it doesn't exist\n",
    "    \n",
    "    # Add prefix and suffix\n",
    "    if prefix:\n",
    "        name = prefix + name\n",
    "    if suffix:\n",
    "        name = name + suffix\n",
    "\n",
    "    # Return the modified file path\n",
    "    return os.path.join(dir_path, name + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e79c1270-9b9c-4403-907d-48db4e38974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_based_on_filename(filenames, conditions, metadata_keys):\n",
    "    \"\"\"\n",
    "    Create a metadata dictionary for each filename based on the matching conditions.\n",
    "\n",
    "    Parameters:\n",
    "        filenames (list): List of filenames to process.\n",
    "        conditions (dict): Dictionary where keys are substrings to match in filenames,\n",
    "                           and values are tuples containing metadata values.\n",
    "        metadata_keys (list): List of keys that define the metadata variables to extract.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary where each filename is mapped to its metadata dictionary.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "\n",
    "    # Iterate over each filename\n",
    "    for filename in filenames:\n",
    "        filename_lower = filename.lower()\n",
    "        metadata_dict = {}\n",
    "\n",
    "        # Check each condition to see if it matches the filename\n",
    "        for key, condition in conditions.items():\n",
    "            if key.lower() in filename_lower:\n",
    "                # Map the tuple values to the metadata keys\n",
    "                metadata_dict = dict(zip(metadata_keys, condition))\n",
    "\n",
    "        # Add the metadata dictionary for the current filename\n",
    "        metadata[filename] = metadata_dict\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ccf3a-8f47-4c45-ac21-5a9902043caf",
   "metadata": {},
   "source": [
    "# Convert GEOJSON to XLSX and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10700003-b1bb-4cc0-b350-6bd8cdf8514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # To work with file paths\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def geojson_to_xlsx(geojson_file):\n",
    "    # Load GeoJSON data\n",
    "    with open(geojson_file, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "    \n",
    "    # Extract features\n",
    "    features = geojson_data['features']\n",
    "    \n",
    "    # Create a DataFrame from the features\n",
    "    df = pd.json_normalize(features)\n",
    "\n",
    "    xlsx_file = os.path.splitext(geojson_file)[0] + \".xlsx\"\n",
    "\n",
    "    # Save DataFrame to Excel file\n",
    "    df.to_excel(xlsx_file, index=False)\n",
    "    print(f\"GeoJSON data has been converted to {xlsx_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9687556-2b59-442f-809f-70610c6fb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # To work with file paths\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def xlsx_to_geojson_beautifued(xlsx_file):\n",
    "    # Extract the name from the xlsx_file\n",
    "    name = os.path.splitext(os.path.basename(xlsx_file))[0]\n",
    "    geojson_file = os.path.splitext(xlsx_file)[0] + \".geojson\"\n",
    "    \n",
    "    # Load Excel data into a DataFrame\n",
    "    df = pd.read_excel(xlsx_file)\n",
    "\n",
    "    # Ensure required columns are present\n",
    "    required_columns = ['geometry.type', 'geometry.coordinates']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: '{col}' in the Excel file.\")\n",
    "\n",
    "    # Convert each row to a GeoJSON feature\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        geometry = {\n",
    "            \"type\": row['geometry.type'],\n",
    "            \"coordinates\": json.loads(row['geometry.coordinates'])  # Parse coordinates from string to Python object\n",
    "        }\n",
    "        # Collect all properties except the geometry columns\n",
    "        property_columns = [col for col in df.columns if col not in required_columns]\n",
    "        properties = row[property_columns].to_dict()\n",
    "\n",
    "        # replacing the text \"properties.\" from each column name\n",
    "        properties = {col.replace('properties.',''):value for col,value in properties.items()}\n",
    "\n",
    "        # Construct GeoJSON feature\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": properties,\n",
    "            \"geometry\": geometry\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "    # Create the GeoJSON structure\n",
    "    geojson_data = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"name\": name,\n",
    "        \"crs\": {\n",
    "            \"type\": \"name\",\n",
    "            \"properties\": { \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" }\n",
    "        },\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "    # Save GeoJSON data to file\n",
    "    with open(geojson_file, 'w') as f:\n",
    "        json.dump(geojson_data, f, indent=4)\n",
    "    print(f\"Excel data has been converted to {geojson_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb840517-8430-46fd-9d76-11bba25e2add",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_geojson = r'D:\\PhenoCrop\\3_qgis\\3_Extraction Polygons\\3. FINAL MASKS PYTHON\\24 ProteinBar Vollebekk 20 sorter 7m_sorted_ID_polygons_shrinked.geojson'\n",
    "path_xlsx = r'D:\\PhenoCrop\\3_qgis\\3_Extraction Polygons\\3. FINAL MASKS PYTHON\\24 PRO_BAR_VOLL Full Field ProteinBar Vollebekk 20 sorter + NAPE 7m_sorted_ID_polygons_shrinked.xlsx'\n",
    "\n",
    "# path = r\"D:\\OLF PHENO\\GCPs Pheno 2019-2023.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83372c3-8fd3-4732-86c9-d05d3201faca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON data has been converted to D:\\PhenoCrop\\3_qgis\\3_Extraction Polygons\\3. FINAL MASKS PYTHON\\24 ProteinBar Vollebekk 20 sorter 7m_sorted_ID_polygons_shrinked.xlsx\n"
     ]
    }
   ],
   "source": [
    "geojson_to_xlsx(path_geojson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3097a5b5-1e29-4c89-aa36-c1ed45a2fb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel data has been converted to D:\\PhenoCrop\\3_qgis\\3_Extraction Polygons\\3. FINAL MASKS PYTHON\\24 PRO_BAR_VOLL Full Field ProteinBar Vollebekk 20 sorter + NAPE 7m_sorted_ID_polygons_shrinked.geojson\n"
     ]
    }
   ],
   "source": [
    "xlsx_to_geojson_beautifued(path_xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ca973-04c2-4cbe-9653-86b19cfc0359",
   "metadata": {},
   "source": [
    "# Import Data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15a5dc1f-eb6b-4ad9-825c-25c2a47320c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r\"sowing\\24 Gene2Bread.geojson\"\n",
    "# input_file = r\"sowing\\24 OatsFrontier.geojson\"\n",
    "# input_file = r\"sowing\\24 PhenoCrop Avlingsregistrering.geojson\"\n",
    "# input_file = r\"sowing\\24 Diversity oats.geojson\"\n",
    "# input_file = r\"sowing\\24 ProteinBar Vollebekk 20 sorter 7m.geojson\"\n",
    "# input_file = r\"sowing\\24 ProteinBar NAPE 7m.geojson\"\n",
    "# input_file = r\"sowing\\24 Soraas - ProteinBar.geojson\"\n",
    "# input_file = r\"sowing\\24 E166.geojson\"\n",
    "\n",
    "# Naming the input and output files\n",
    "# Generate centroids\n",
    "output_cenroids = modify_filename(input_file, \"1_\", \"_centroids\", output_subfolder)\n",
    "# Reorder the centroids\n",
    "input_centroids = output_cenroids\n",
    "output_ordered_centroids = modify_filename(input_file, \"2_\", \"_centroids_ordered\", output_subfolder)\n",
    "# Update the IDs\n",
    "input_ordered_centroids = output_ordered_centroids\n",
    "output_centroids_with_IDs = modify_filename(input_file, \"3_\", \"_centroids_IDs\", output_subfolder)\n",
    "# Generate the shrinked polygons\n",
    "input_centroids_with_IDs = output_centroids_with_IDs\n",
    "output_extraction_polygons = modify_filename(input_file, \"4_\", \"_polygons_shrinked\", output_subfolder)\n",
    "\n",
    "id_start=100\n",
    "id_end=126\n",
    "step=100\n",
    "\n",
    "entry_step=1\n",
    "column_step=100\n",
    "\n",
    "# Set your desired width, height, and rotation angle (in degrees)\n",
    "width = 9.5  # Specify width of the rectangle\n",
    "height = 2.1  # Specify height of the rectangle\n",
    "rotation = 12  # Specify rotation angle of the polygons in degrees\n",
    "rotation_angle = -23   # Specify rotation angle of the whole grid in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "514e9ae3-5ba4-425f-9309-bf517842ba58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping field TIME: unsupported OGR type: 10\n",
      "C:\\NMBU\\TEMP\\ipykernel_5036\\3266098228.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "# Performing the centroid operations\n",
    "polygons_to_centroids(input_file, output_cenroids) # Find the centroid of the sowing polygons\n",
    "reorder_points_by_columns(input_centroids, output_ordered_centroids, rotation_grid_for_ordering)  # Reorder the centroids. Adjust rotation_angle as needed\n",
    "update_ids(input_ordered_centroids, output_centroids_with_IDs, id_start, id_end, step)  # Update the IDs\n",
    "\n",
    "# Generate the shrinked polygons\n",
    "generate_shrinked_polygons(input_centroids_with_IDs,\n",
    "                            output_extraction_polygons,\n",
    "                            width,\n",
    "                            height,\n",
    "                            rotation_polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33448488-201a-4a62-9c9b-01aa388e6323",
   "metadata": {},
   "source": [
    "# Organising all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b44ae083-e617-41cb-9a99-057e24d88ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sowing\\\\24 Diversity oats_sorted_ID.geojson',\n",
       " 'sowing\\\\24 E166_sorted_ID_corrected_coordinate_system.geojson',\n",
       " 'sowing\\\\24 Gene2Bread_sorted_ID.geojson',\n",
       " 'sowing\\\\24 OatsFrontier_sorted_ID.geojson',\n",
       " 'sowing\\\\24 PhenoCrop Avlingsregistrering_sorted_ID.geojson',\n",
       " 'sowing\\\\24 ProteinBar NAPE 7m_sorted_ID.geojson',\n",
       " 'sowing\\\\24 ProteinBar Vollebekk 20 sorter 7m_sorted_ID.geojson',\n",
       " 'sowing\\\\24 Soraas - ProteinBar_sorted_ID.geojson']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_folder = r\"sowing\"\n",
    "sowing_files = find_files_in_folder(source_folder, 'geojson')\n",
    "sowing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82ed932c-d3a6-4433-aae6-e4cfbf251bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\PhenoCrop\\\\3_qgis\\\\3_Extraction Polygons\\\\24 E166_sorted_ID_corrected_coordinate_system.geojson',\n",
       " 'D:\\\\PhenoCrop\\\\3_qgis\\\\3_Extraction Polygons\\\\E166 ORG.geojson']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_folder = r\"D:\\PhenoCrop\\3_qgis\\3_Extraction Polygons\"\n",
    "sowing_files = find_files_in_folder(source_folder, 'geojson')\n",
    "sowing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "242bee3e-ac88-48d9-a519-309553aa64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to D:\\PhenoCrop\\3_qgis\\3_Extraction Polygons\\2_4 E166_sorted_ID_corrected_coordinate_system.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muij\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: Several features with id = 1 have been found. Altering it to be unique. This warning will not be emitted anymore for this layer\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "    generate_shrinked_polygons(sowing_files[1],\n",
    "                                r\"D:\\PhenoCrop\\3_qgis\\3_Extraction Polygons\\2_4 E166_sorted_ID_corrected_coordinate_system.geojson\",\n",
    "                                12,\n",
    "                                5,\n",
    "                                114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ed5c53ee-eeb4-446e-85e1-bd4e67126ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping field TIME: unsupported OGR type: 10\n",
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to sowing\\extraction\\4_24 Diversity oats_sorted_ID_polygons_shrinked.geojson\n",
      "Shrinked polygons saved to sowing\\extraction\\4_24 E166_sorted_ID_corrected_coordinate_system_polygons_shrinked.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n",
      "Skipping field TIME: unsupported OGR type: 10\n",
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n",
      "Skipping field TIME: unsupported OGR type: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to sowing\\extraction\\4_24 Gene2Bread_sorted_ID_polygons_shrinked.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n",
      "Skipping field TIME: unsupported OGR type: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to sowing\\extraction\\4_24 OatsFrontier_sorted_ID_polygons_shrinked.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to sowing\\extraction\\4_24 PhenoCrop Avlingsregistrering_sorted_ID_polygons_shrinked.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n",
      "Skipping field TIME: unsupported OGR type: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to sowing\\extraction\\4_24 ProteinBar NAPE 7m_sorted_ID_polygons_shrinked.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n",
      "Skipping field TIME: unsupported OGR type: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to sowing\\extraction\\4_24 ProteinBar Vollebekk 20 sorter 7m_sorted_ID_polygons_shrinked.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\NMBU\\TEMP\\ipykernel_13968\\2641132132.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinked polygons saved to sowing\\extraction\\4_24 Soraas - ProteinBar_sorted_ID_polygons_shrinked.geojson\n"
     ]
    }
   ],
   "source": [
    "# SKIPPED DOING ORDERING USING PYTHON. RATHER CONVERTED ALL GEOJSON TO XLSX AND ADDED THE IDS IN EXCEL AND CONVERTED BACK ALL THE FILES BACK TO GEOJSON.\n",
    "# SKIPPING THE ORDERING AND UPDATING IDs process here.\n",
    "\n",
    "# NOTES FROM BEFORE =DISCARD=\n",
    "# ORDERING IS SOMEHOW REVERESED  \"ProteinBar Vollebekk\"\n",
    "# ORDERING NOT CORRECT \"ProteinBar NAPE\"\n",
    "# PLOTS ARE ORDERED BUT NEED TO CHECK AND CORRECT THE IDs \"E166\"\n",
    "# PLOTS NUMBER IS REVERSER BUT THE ORDER SEEMS CORRECT \"Soraas\"\n",
    "# DIVERSITY NEED TO FIGURE OUT A LOGIC FOR NUMBERING\n",
    "\n",
    "\n",
    "source_folder_sowing_geojson = r\"sowing\"\n",
    "output_subfolder = \"extraction\"\n",
    "\n",
    "#SIMPLE UNIQUE ID SYSTEM WITH START, ENF AND COLUMN STEP\n",
    "metadata_keys = [\"field\", \"id_start\", \"id_end\", \"step\", \"width\", \"height\", \"rotation_polygons\", \"rotation_grid_for_ordering\"]\n",
    "conditions = {\n",
    "    \"PhenoCrop\": (\"PhenoCrop\", 100, 196, 100, 9.5, 2.1, 12, -23),\n",
    "    \"Frontier\": (\"Frontier\", 100, 111, 100, 9.5, 2.1, 12, -23),\n",
    "    \"Gene2Bread\": (\"Gene2Bread\", 100, 126, 100, 9.5, 2.1, 12, -23),\n",
    "    \"Diversity\": (\"Diversity\", 132, 100, -1, 2, 2, 12, -23), # ID End does not work due to unusual design\n",
    "    \"ProteinBar Vollebekk\": (\"ProteinBar Vollebekk\", 1100, 1122, 100, 13, 2.1, 28, -46.5), \n",
    "    \"ProteinBar NAPE\": (\"ProteinBar NAPE\", 101, 120, 100, 13.25, 2, 28, -46.5),  # Dont have the sowing shape files for this field. Generated the centroids menually\n",
    "    \"E166\": (\"E166\", 1, 13, 0, 13, 3, 114, -116), # The original sowing shape files not found. These are based on the manually shrinked polygons created by students in 2024.\n",
    "                                                    # The ID Logic is tricky for this one\n",
    "    \"Soraas\": (\"Soraas\", 101000, 101089, 1000, 9.5, 2.1, 67, -78),\n",
    "}\n",
    "\n",
    "sowing_files = find_files_in_folder(source_folder_sowing_geojson, 'geojson')\n",
    "metadata_dict = create_metadata_based_on_filename(sowing_files, conditions, metadata_keys)\n",
    "\n",
    "for file_path, variables in metadata_dict.items():\n",
    "    input_file = file_path\n",
    "    # Declare variables for each metadata field\n",
    "    for var_name, value in variables.items():\n",
    "        globals()[var_name] = value\n",
    "    file_path, field, id_start, id_end, step, width, height, rotation_polygons, rotation_grid_for_ordering\n",
    "\n",
    "    # Naming the input and output files\n",
    "    # Generate centroids\n",
    "    output_cenroids = modify_filename(input_file, \"1_\", \"_centroids\", output_subfolder)\n",
    "    # Reorder the centroids\n",
    "    output_ordered_centroids = modify_filename(input_file, \"2_\", \"_centroids_ordered\", output_subfolder)\n",
    "    # Update the IDs\n",
    "    output_centroids_with_IDs = modify_filename(input_file, \"3_\", \"_centroids_IDs\", output_subfolder)\n",
    "    # Generate the shrinked polygons\n",
    "    output_extraction_polygons = modify_filename(input_file, \"4_\", \"_polygons_shrinked\", output_subfolder)\n",
    "\n",
    "\n",
    "    # Performing the centroid operations\n",
    "    polygons_to_centroids(input_file, output_cenroids) # Find the centroid of the sowing polygons\n",
    "    if not \"_sorted_id\" in file_path.lower():\n",
    "        print(\"here\", file_path.lower())\n",
    "        reorder_points_by_columns(output_cenroids, output_ordered_centroids, rotation_grid_for_ordering)  # Reorder the centroids. Adjust rotation_angle as needed\n",
    "        if not \"diversity\" in file_path.lower():\n",
    "            update_ids(output_ordered_centroids, output_centroids_with_IDs, id_start, id_end, step)  # Update the IDs\n",
    "        else:\n",
    "            output_centroids_with_IDs = output_ordered_centroids\n",
    "    else:\n",
    "        output_centroids_with_IDs = output_cenroids\n",
    "\n",
    "    # Generate the shrinked polygons\n",
    "    generate_shrinked_polygons(output_centroids_with_IDs,\n",
    "                                output_extraction_polygons,\n",
    "                                width,\n",
    "                                height,\n",
    "                                rotation_polygons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
